# üß¨ NeuroDiscoveryBench

NeuroDiscoveryBench is an open benchmark designed to evaluate how well AI systems can analyze real world neuroscience, genetics, and immunology datasets to generate scientific insights. The benchmark includes both text- and figure-based tasks, modeled after real world workflows that involve data manipulation, data analysis, and visualization. 

It builds on landmark open datasets by the Allen Institute and includes workflows derived from following papers:

- Yao, Z., van Velthoven, C.T.J., Kunst, M. et al. A high-resolution transcriptomic and spatial atlas of cell types in the whole mouse brain. Nature 624, 317‚Äì332 (2023). https://doi.org/10.1038/s41586-023-06812-z

- Klunk, J., Vilgalys, T.P., Demeure, C.E. et al. Evolution of immune genes is associated with the Black Death. Nature 611, 312‚Äì319 (2022). https://doi.org/10.1038/s41586-022-05349-x

- Gabitto, M.I., Travaglini, K.J., Rachleff, V.M. et al. Integrated multimodal cell atlas of Alzheimer‚Äôs disease. Nat Neurosci 27, 2366‚Äì2383 (2024). https://doi.org/10.1038/s41593-024-01774-5


<img width="746" alt="image" src="https://github.com/user-attachments/assets/26968034-a19b-4508-944e-9bb70020428d" />


## üöÄ Getting Started

### 1. Setup python virtual environment

Create a Python virtual environment to isolate your work with NeuroDiscoveryBench and avoid dependency conflicts with your global Python environment:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip3 install -r requirements.txt
```

If you use `uv` package manager, use these following commands to set up the virtual environment:

```bash
uv venv
source .venv/bin/activate
uv pip3 install -r requirements.txt
```

### 2. Download the dataset files

Some large data files are hosted on Google Drive. To download and set them up, run the following script:

```bash
python3 utils/bio_data_loader.py
```

### 3. Running Baseline Agents

To run the baseline agents, use the `baseline_agents/main.py` script with the following configurations:

``` bash
python3 main.py --help
```
The output will show the following options:
```

Usage: main.py [OPTIONS]

  Run a neurodiscovery benchmarking agent.

Options:
  --agent_name TEXT                The name of the agent to use. Must be one
                                   of: "no_data_agent", "no_data_and_search_agent".
                                   [required]

  --config_file PATH               Path to the YAML configuration file defining
                                   agent parameters. See `baseline_agents/no_data_agent/config/`
                                   for reference. [required]

  --data_dir PATH                  Directory containing benchmark data.
                                   [default: "neurodiscoverybench"]

  --provide_domain_knowledge       If set, the agent will be provided with
                                   additional domain knowledge in each query.

  --provide_workflow_tags          If set, workflow tags (metadata about
                                   experiment steps) will be included in
                                   query.

  --output_csv_path TEXT           Name for the output CSV file that will hold
                                   the generated hypotheses and images. This CSV
                                   will be used as input for evaluating the agent logs.

  --help                           Show this message and exit.
```

> [!NOTE]
> Please note that if requisite data files are not downloaded, the agents will automatically download and set them up. 

### 4. Running the DataVoyager Agent

TBA (To Be Added) based on DV lib

### 5. Evaluating Agent-Generated Results

To evaluate the results generated by the agent, use the following command:

```bash
python3 eval/eval.py --help
```
The output will show:
```bash
Usage: eval.py [OPTIONS]

  Evaluate agent-generated hypotheses and compute scores for each task.

Options:
  --agent_results_csv PATH   Path to the CSV file produced by the agent run.
                             The file should contain tasks and corresponding
                             generated hypotheses.  [required]

  --output_csv PATH          Path to save the evaluated CSV file. If not
                             provided, a new file with "_evaluated" suffix
                             will be created next to the input file.

  --help                     Show this message and exit.

```


## ü§ó Huggingface
Explore BioDiscoveryBench at Huggingface's data viewer TBA

## ‚úçÔ∏è Citation

TBA
